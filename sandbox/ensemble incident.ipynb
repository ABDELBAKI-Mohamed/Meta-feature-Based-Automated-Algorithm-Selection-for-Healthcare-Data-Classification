{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf = pd.read_csv(\"cleaned_metadf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = metadf.drop('algorithm',axis=1)\n",
    "y = metadf['algorithm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is the target variable\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "# Initialize the individual models with random state 33\n",
    "rf_model = RandomForestClassifier(n_estimators=10, max_depth=11, random_state=42)\n",
    "ada_model = AdaBoostClassifier(n_estimators=100, random_state=33)\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=100, random_state=33)\n",
    "\n",
    "# Fit the individual models on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "ada_model.fit(X_train, y_train)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with each model on the testing data\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "ada_pred = ada_model.predict(X_test)\n",
    "gbm_pred = gbm_model.predict(X_test)\n",
    "\n",
    "# Create an ensemble by taking the mode (most frequent class) of the predictions from the three models\n",
    "ensemble_pred = np.array([rf_pred, ada_pred, gbm_pred])\n",
    "final_predictions = mode(ensemble_pred, axis=0).mode.flatten()\n",
    "\n",
    "# Calculate the accuracy of the ensemble\n",
    "ensemble_accuracy = accuracy_score(y_test, final_predictions)\n",
    "\n",
    "# Display the accuracy of each individual model and the ensemble\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, ada_pred))\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gbm_pred))\n",
    "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
    "\n",
    "# You can also print other evaluation metrics such as classification report or confusion matrix\n",
    "print(\"\\nEnsemble Classification Report:\")\n",
    "print(classification_report(y_test, final_predictions))\n",
    "\n",
    "print(\"\\nEnsemble Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, final_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores (Random Forest):  [0.6470588235294118, 0.5882352941176471, 0.5625, 0.625, 0.4375]\n",
      "Average Accuracy (Random Forest):  0.5720588235294117\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cross_val_with_oversampling(classifier, X, y, n_splits=5, random_state=42):\n",
    "    # Convert X and y to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Perform stratified k-fold cross-validation\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Initialize the oversampler\n",
    "    oversampler = RandomOverSampler(random_state=random_state)\n",
    "\n",
    "    # Initialize lists to store the accuracy scores for each fold\n",
    "    cv_scores = []\n",
    "\n",
    "    # Perform cross-validation with class oversampling\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Perform class oversampling on the training set\n",
    "        X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Fit the classifier on the resampled data\n",
    "        classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        fold_accuracy = accuracy_score(y_test, y_pred)\n",
    "        cv_scores.append(fold_accuracy)\n",
    "\n",
    "    # Return the cross-validation accuracy scores\n",
    "    return cv_scores\n",
    "\n",
    "# Example usage with RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming you have already loaded your dataset into X (features) and y (labels) arrays\n",
    "random_state = 42\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, max_depth=11, random_state=random_state)\n",
    "\n",
    "cv_scores_rf = cross_val_with_oversampling(rf_classifier, X, y, random_state=random_state)\n",
    "\n",
    "print(\"Cross-validation Accuracy Scores (Random Forest): \", cv_scores_rf)\n",
    "print(\"Average Accuracy (Random Forest): \", np.mean(cv_scores_rf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1961d10655999fc8e87af894448e5d9193e8f562985b7a28acbe1118e322c92a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
